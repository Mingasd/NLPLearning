{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('wind', 'VBP'),\n",
       " ('back', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('clock', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('chase', 'VBP'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wind', 'NN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "sent = 'They wind back the clock,while we chase after the wind'\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'123': 123}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6\n",
    "d = {}\n",
    "d['123'] = 123\n",
    "d['abc'] = 'abc'\n",
    "del d['abc']\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'a', 'b': 'b'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "d2['a'] = 'a'\n",
    "d2['b'] = 'b'\n",
    "d1.update(d2)\n",
    "d1\n",
    "# 将d2中的条目全部添加到d1中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
      "Displaying 25 of 194 matches:\n",
      "by so much the more shall ye for ever go thankless ! Would that I could clear \n",
      "wallow up Jonah .\" -- JONAH . \" There go the ships ; there is that Leviathan w\n",
      "ur children ' s grand - children will go for bread .\" -- OBED MACY ' S HISTORY\n",
      " city of a dreamy Sabbath afternoon . Go from Corlears Hook to Coenties Slip ,\n",
      "ed upon the magic stream before him . Go visit the Prairies in June , when for\n",
      " him , at some time or other crazy to go to sea ? Why upon your first voyage a\n",
      " mean to have it inferred that I ever go to sea as a passenger . For to go as \n",
      "ver go to sea as a passenger . For to go as a passenger you must needs have a \n",
      ", as a general thing ;-- no , I never go as a passenger ; nor , though I am so\n",
      " I am something of a salt , do I ever go to sea as a Commodore , or a Captain \n",
      "e - houses the pyramids . No , when I go to sea , I go as a simple sailor , ri\n",
      " pyramids . No , when I go to sea , I go as a simple sailor , right before the\n",
      "s , and be content . Again , I always go to sea as a sailor , because they mak\n",
      "ves to perdition ! Finally , I always go to sea as a sailor , because of the w\n",
      " I should now take it into my head to go on a whaling voyage ; this the invisi\n",
      "ieces of silver ,-- So , wherever you go , Ishmael , said I to myself , as I s\n",
      " of the tinkling glasses within . But go on , Ishmael , said I at last ; don '\n",
      "line of the equator ; yea , ye gods ! go down to the fiery pit itself , in ord\n",
      "nd town ?-- but turn flukes again and go to sleep . Queequeg , look here -- yo\n",
      "ight , landlord ,\" said I , \" you may go .\" I turned in , and never slept bett\n",
      "us of stepmothers , and back I had to go to my room . For several hours I lay \n",
      "inched and tormented him at the first go off of a bitter cold morning . Seeing\n",
      "is once scraggy scoria of a country ? Go and gaze upon the iron emblematical h\n",
      " a few porpoises a - piece . You must go to New Bedford to see a brilliant wed\n",
      "es and all the world . But we did not go to sleep without some little chat . H\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "from nltk.book import *\n",
    "text1.concordance('go')\n",
    "text1.concordance('went')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PPSS'),\n",
       " ('wind', 'VB'),\n",
       " ('back', 'RB'),\n",
       " ('the', 'AT'),\n",
       " ('clock', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'CS'),\n",
       " ('we', 'PPSS'),\n",
       " ('chase', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('wind', 'VB')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "brown_sents = brown.sents(categories = 'news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', None),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('terrace', 'NN'),\n",
       " ('type', None),\n",
       " (',', None),\n",
       " ('being', 'VBG'),\n",
       " ('on', None),\n",
       " ('the', None),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', None),\n",
       " ('that', None),\n",
       " ('entrance', 'NN'),\n",
       " ('is', None),\n",
       " ('direct', 'NN'),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11\n",
    "affixtagger=nltk.AffixTagger(brown_tagged_sents)\n",
    "affixtagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-8-15\n"
     ]
    }
   ],
   "source": [
    "# 13\n",
    "d={'year':2016,'month':8,'day':15}\n",
    "print ('%s-%s-%s' % (d['year'],d['month'],d['day']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f374f6850058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'brown' is not defined"
     ]
    }
   ],
   "source": [
    "# 14\n",
    "sorted(set(brown.words(categories='news')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
