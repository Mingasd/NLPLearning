{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('compeletely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用词性标注器\n",
    "text = nltk.word_tokenize(\"And now for something compeletely different\")\n",
    "nltk.pos_tag(text)\n",
    "\n",
    "# CC - 并列连词\n",
    "# RB - 副词\n",
    "# IN - 介词\n",
    "# NN - 名词\n",
    "# JJ - 形容词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize('They refuse to permit us to obtain the refuse permit')\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标注语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fly', 'NN')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 表示已标注的标识符\n",
    "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取已标注的语料库\n",
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'VBD', 'NR', 'NN', 'IN', 'NP$', 'JJ', '``', \"''\", 'CS', 'DTI', 'NNS', '.', 'RBR', ',', 'WDT', 'HVD', 'VBZ', 'CC', 'IN-TL', 'BEDZ', 'VBN', 'NP', 'BEN', 'TO', 'VB', 'RB', 'DT', 'PPS', 'DOD', 'AP', 'BER', 'HV', 'DTS', 'VBG', 'PPO', 'QL', 'JJT', 'ABX', 'NN-HL', 'VBN-HL', 'WRB', 'CD', 'MD', 'BE', 'JJR', 'VBG-TL', 'BEZ', 'NN$-TL', 'HVZ', 'ABN', 'PN', 'PPSS', 'PP$', 'DO', 'NN$', 'NNS-HL', 'WPS', '*', 'EX', 'VB-HL', ':', '(', ')', 'NNS-TL', 'NPS', 'JJS', 'RP', '--', 'BED', 'OD', 'BEG', 'AT-HL', 'VBG-HL', 'AT-TL', 'PPL', 'DOZ', 'NP-HL', 'NR$', 'DOD*', 'BEDZ*', ',-HL', 'CC-TL', 'MD*', 'NNS$', 'PPSS+BER', \"'\", 'PPSS+BEM', 'CD-TL', 'RBT', '(-HL', ')-HL', 'MD-HL', 'VBZ-HL', 'IN-HL', 'JJ-HL', 'PPLS', 'CD-HL', 'WPO', 'JJS-TL', 'ABL', 'BER-HL', 'PPS+HVZ', 'VBD-HL', 'RP-HL', 'MD*-HL', 'AP-HL', 'CS-HL', 'DT$', 'HVN', 'FW-IN', 'FW-DT', 'VBN-TL', 'NR-TL', 'NNS$-TL', 'FW-NN', 'HVG', 'DTX', 'OD-TL', 'BEM', 'RB-HL', 'PPSS+MD', 'NPS-HL', 'NPS$', 'WP$', 'NN-TL-HL', 'CC-HL', 'PPS+BEZ', 'AP-TL', 'UH-TL', 'BEZ-HL', 'TO-HL', 'DO*', 'VBN-TL-HL', 'NNS-TL-HL', 'DT-HL', 'BE-HL', 'DOZ*', 'QLP', 'JJR-HL', 'PPSS+HVD', 'FW-IN+NN', 'PP$$', 'JJT-HL', 'NP-TL-HL', 'NPS-TL', 'MD+HV', 'NP$-TL', 'OD-HL', 'JJR-TL', 'VBD-TL', 'DT+BEZ', 'EX+BEZ', 'PPSS+HV', ':-HL', 'PPS+MD', 'UH', 'FW-CC', 'FW-NNS', 'BEDZ-HL', 'NN$-HL', '.-HL', 'HVD*', 'BEZ*', 'AP$', 'NP+BEZ', 'FW-AT-TL', 'VB-TL', 'RB-TL', 'MD-TL', 'PN+HVZ', 'FW-JJ-TL', 'FW-NN-TL', 'ABN-HL', 'PPS+BEZ-HL', 'NR-HL', 'HVD-HL', 'RB$', 'FW-AT-HL', 'DO-HL', 'PP$-TL', 'FW-IN-TL', 'WPS+BEZ', '*-HL', 'DTI-HL', 'PN-HL', 'CD$', 'BER*', 'NNS$-HL', 'PN$', 'BER-TL', 'TO-TL', 'FW-JJ', 'BED*', 'RB+BEZ', 'VB+PPO', 'PPSS-HL', 'HVZ*', 'FW-IN+NN-TL', 'FW-IN+AT-TL', 'NN-NC', 'JJ-NC', 'NR$-TL', 'FW-PP$-NC', 'FW-VB', 'FW-VB-NC', 'JJR-NC', 'NPS$-TL', 'QL-TL', 'FW-AT', 'FW-*', 'FW-CD', 'WQL', 'FW-WDT', 'WDT+BEZ'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 简化的词性标记集\n",
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories = 'news')\n",
    "tag_fd = nltk.FreqDist(tag for (word,tag) in brown_news_tagged)\n",
    "tag_fd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'accomplished',\n",
       " 'analytically',\n",
       " 'appear',\n",
       " 'apt',\n",
       " 'associated',\n",
       " 'assuming',\n",
       " 'became',\n",
       " 'become',\n",
       " 'been',\n",
       " 'began',\n",
       " 'call',\n",
       " 'called',\n",
       " 'carefully',\n",
       " 'chose',\n",
       " 'classified',\n",
       " 'colorful',\n",
       " 'composed',\n",
       " 'contain',\n",
       " 'differed',\n",
       " 'difficult',\n",
       " 'encountered',\n",
       " 'enough',\n",
       " 'equate',\n",
       " 'extremely',\n",
       " 'found',\n",
       " 'happens',\n",
       " 'have',\n",
       " 'ignored',\n",
       " 'in',\n",
       " 'involved',\n",
       " 'more',\n",
       " 'needed',\n",
       " 'nightly',\n",
       " 'observed',\n",
       " 'of',\n",
       " 'on',\n",
       " 'out',\n",
       " 'quite',\n",
       " 'represent',\n",
       " 'responsible',\n",
       " 'revamped',\n",
       " 'seclude',\n",
       " 'set',\n",
       " 'shortened',\n",
       " 'sing',\n",
       " 'sounded',\n",
       " 'stated',\n",
       " 'still',\n",
       " 'sung',\n",
       " 'supported',\n",
       " 'than',\n",
       " 'to',\n",
       " 'when',\n",
       " 'work']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 探索已标注的语料库\n",
    "brown_learned_text = brown.words(categories = 'learned')\n",
    "sorted(set(b for (a,b) in nltk.bigrams(brown_learned_text) if a == 'often'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBN  VB VBD  JJ  IN  QL   ,  CS  RB  AP VBG  RP VBZ QLP BEN WRB   .  TO  HV \n",
      " 15  10   8   5   4   3   3   3   3   1   1   1   1   1   1   1   1   1   1 \n"
     ]
    }
   ],
   "source": [
    "brown_lrnd_tagged = brown.tagged_words(categories = 'learned')\n",
    "tags = [b[1] for (a,b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'often']\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VBN'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认标注器\n",
    "raw = 'I do not like green eggs and ham,'\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一元标注\n",
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "brown_sents = brown.sents(categories = 'news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])\n",
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般的N-gram标注\n",
    "size = int(len(brown_tagged_sents)*0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('population', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('Congo', 'NP'),\n",
       " ('is', 'BEZ'),\n",
       " ('13.5', None),\n",
       " ('million', None),\n",
       " (',', None),\n",
       " ('divided', None),\n",
       " ('into', None),\n",
       " ('at', None),\n",
       " ('least', None),\n",
       " ('seven', None),\n",
       " ('major', None),\n",
       " ('``', None),\n",
       " ('culture', None),\n",
       " ('clusters', None),\n",
       " (\"''\", None),\n",
       " ('and', None),\n",
       " ('innumerable', None),\n",
       " ('tribes', None),\n",
       " ('speaking', None),\n",
       " ('400', None),\n",
       " ('separate', None),\n",
       " ('dialects', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sent = brown_sents[4203]\n",
    "bigram_tagger.tag(unseen_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10206319146815508"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.evaluate(test_sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
